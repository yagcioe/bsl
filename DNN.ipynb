{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.config.list_physical_devices('CPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config variables\n",
    "randomSeed = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadInputData(path: str):\n",
    "    pass\n",
    "\n",
    "# transforms a WAV file into a npArray of shape(1, F, 3) (Time, Feq, Hue)\n",
    "def fourierTransform(wav):\n",
    "    pass\n",
    "\n",
    "# normalizes, so every Component of the furier transform is in [0,1]\n",
    "def normalizeFurierTransform():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_input, train_label), (test_input, test_label) = boston_housing.load_data(test_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = [np.amax(train_input[:,i]) for i in range(train_input.shape[1])]\n",
    "print(max_input)\n",
    "normalizedTrainInput = train_input / max_input\n",
    "normalizedTrainLabel= train_label / np.amax(train_label)\n",
    "print(normalizedTrainInput)\n",
    "normalizedTestInput= test_input/max_input\n",
    "normalizedTestLabels = test_label / np.amax(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not randomSeed:\n",
    "    np.random.seed(1234)\n",
    "shuffler= np.random.permutation(len(normalizedTrainLabel))\n",
    "\n",
    "normalizedTrainInput = normalizedTrainInput[shuffler]\n",
    "normalizedTrainLabel = normalizedTrainLabel[shuffler]\n",
    "\n",
    "validation_split= 0.8/0.4\n",
    "\n",
    "validation_input = normalizedTrainInput[:int(np.floor(normalizedTestInput.shape[0]/validation_split))]\n",
    "validation_label = normalizedTrainLabel[:int(np.floor(normalizedTestLabels.size/validation_split))]\n",
    "\n",
    "train_input = normalizedTrainInput[int(np.ceil(normalizedTestInput.shape[0]/validation_split)):]\n",
    "train_label = normalizedTrainLabel[int(np.ceil(normalizedTestLabels.size/validation_split)):]\n",
    "\n",
    "test_input =  normalizedTestInput\n",
    "test_label = normalizedTestLabels\n",
    "\n",
    "print(validation_input[:5])\n",
    "print(validation_label[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(32, input_shape=(13,)))\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss=keras.losses.MSE,\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_input,train_label,batch_size=101,epochs=100, validation_data=(validation_input, validation_label), verbose=0)\n",
    "history_dic = history.history\n",
    "print(history_dic)\n",
    "evalutaion = model.evaluate(test_input,test_label,batch_size=101)\n",
    "print(evalutaion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(3, len(history_dic['mean_absolute_error'])),\n",
    "         history_dic['mean_absolute_error'][3:], 'bo', label='train')\n",
    "plt.plot(range(3, len(history_dic['val_mean_absolute_error'])),\n",
    "         history_dic['val_mean_absolute_error'][3: ], 'b', label='val')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.plot(range(3, len(history_dic['loss'])),\n",
    "         history_dic['loss'][3:], 'bo', label=\"train\")\n",
    "plt.plot(range(3, len(history_dic['val_loss'])),\n",
    "         history_dic['val_loss'][3:], 'b', label='val')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb449e53dd372215b80e7ed3be416481dfeee2fd742bfe6369d3120d1b21554b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
