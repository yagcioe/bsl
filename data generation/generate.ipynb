{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile\n",
    "import json\n",
    "import textgrid\n",
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.directivities \\\n",
    "    import (CardioidFamily, DirectionVector, DirectivityPattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script parameters\"\"\"\n",
    "target_amount_samples = 250\n",
    "skipSamples = 0\n",
    "target_dir = '/workspace/training/KEC'\n",
    "\n",
    "\n",
    "\"Persons\"\n",
    "speakers_in_room = 1\n",
    "\n",
    "\"ROOM\"\n",
    "# size of the Listeners head\n",
    "head_size = 0.2\n",
    "\n",
    "randomize_room = False\n",
    "# room generation will be laplace distributed in these intervalls [width, length, height]\n",
    "normal_room_dim = [15, 20, 4]\n",
    "room_dim_ranges = [[3, 30], [3, 30], [2.5, 5]]\n",
    "\n",
    "# The amout Walls absorb Sound\n",
    "normal_absorption = 1.2\n",
    "absorption_range = [1, 2]\n",
    "\n",
    "# the time it take until the signal drops by 60 dB\n",
    "normal_rt60 = 0.25\n",
    "rt60_range = [0.05, 0.75]\n",
    "\n",
    "\"AUdio\"\n",
    "sampleRate = 16000\n",
    "#total_length = 30\n",
    "max_audio_length = 30\n",
    "#min_audio_length = 5\n",
    "min_characters_per_sentence = 20\n",
    "\n",
    "\n",
    "# 'nice to have' for data generation\n",
    "source_dataset = 'KEC - https://clarin.phonetik.uni-muenchen.de/BASRepository/index.php?target=Public/Corpora/KEC/KEC.1.php'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualization\"\"\"\n",
    "def scatterplot3d(points, dims):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_xlim(0,dims[0])\n",
    "    ax.set_ylim(0,dims[1])\n",
    "    ax.set_zlim(0,dims[2])\n",
    "\n",
    "    for p in points:\n",
    "        ax.scatter(p[0],p[1],p[2])\n",
    "    plt.show()\n",
    "    plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Util\"\"\"\n",
    "def rec_filter(x):\n",
    "    return True if 'rec' in x else False\n",
    "\n",
    "\n",
    "def wav_filter(x):\n",
    "    return True if '.wav' in x else False\n",
    "\n",
    "\n",
    "def txt_filter(x):\n",
    "    return True if '.TextGrid' in x else False\n",
    "\n",
    "\n",
    "def as_filter(x):\n",
    "    return True if 'AS' in x else False\n",
    "\n",
    "\n",
    "def idx_filter_txt(x, y):\n",
    "    return True if x[len(x) - 10] == y else False\n",
    "\n",
    "\n",
    "def rec_filter(x):\n",
    "    return True if 'rec' in x else False\n",
    "\n",
    "\n",
    "def norm2(x):\n",
    "    n = np.sum(list(map(lambda y: y**2, x)))\n",
    "    print(n)\n",
    "    return n\n",
    "\n",
    "\n",
    "def distance(x, y):\n",
    "    v = [ x[i]-y[i] for i in range(len(x))]\n",
    "    return norm2(v)\n",
    "\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"Dataset specific Wav Generation\"\n",
    "def FileGeneratorsKEC():\n",
    "    src = '/workspace/data/KEC'\n",
    "    recFolders = list(filter(lambda f: rec_filter(f), os.listdir(src)))\n",
    "    allWavfiles = []\n",
    "    alltxtFiles = []\n",
    "    for rec in recFolders:\n",
    "        currentDir = src+\"/\"+rec\n",
    "\n",
    "        wavFilesOfFolder = list(\n",
    "            filter(lambda f: wav_filter(f), os.listdir(currentDir)))\n",
    "        wavFilesOfFolder = list(\n",
    "            map(lambda f: currentDir+\"/\"+f, wavFilesOfFolder))\n",
    "        allWavfiles.extend(wavFilesOfFolder)\n",
    "\n",
    "        txtFilesOfFolder = list(\n",
    "            filter(lambda f: txt_filter(f), os.listdir(currentDir)))\n",
    "        txtFilesOfFolder = list(\n",
    "            map(lambda f: currentDir+\"/\"+f, txtFilesOfFolder))\n",
    "        alltxtFiles.extend(txtFilesOfFolder)\n",
    "\n",
    "    def wavGen():\n",
    "        for file in allWavfiles:\n",
    "            yield file\n",
    "\n",
    "    def textGen():\n",
    "        for file in alltxtFiles:\n",
    "            yield file\n",
    "\n",
    "    return wavGen, textGen\n",
    "\n",
    "# splits text file in parts\n",
    "\n",
    "\n",
    "def split_sentence(textGrid):\n",
    "    currentTime = 0\n",
    "    sentence_start = 0\n",
    "    sentences, timestamp = [], []\n",
    "    sentence = ''\n",
    "\n",
    "    for t in textGrid[0]:\n",
    "        if currentTime > t.maxTime:\n",
    "            break\n",
    "\n",
    "        currentTime = t.maxTime\n",
    "        if sentence == '':\n",
    "            sentence_start = t.maxTime\n",
    "\n",
    "        sentence += ' ' + t.mark\n",
    "        duration = np.round(t.maxTime - sentence_start, 5)\n",
    "\n",
    "        if '<P>' in t.mark:\n",
    "            if duration < max_audio_length and duration >= 5 and len(sentence) > min_characters_per_sentence:\n",
    "                sentences.append(sentence[:-3].strip())\n",
    "                timestamp.append([sentence_start, t.maxTime, duration])\n",
    "            sentence = ''\n",
    "\n",
    "    return sentences, timestamp\n",
    "\n",
    "\n",
    "def VoiceLineGeneratorKEC(count, voicesPerSample):\n",
    "    wavGen, textGen = FileGeneratorsKEC()\n",
    "    allWavPaths = [p for p in wavGen()]\n",
    "    allTxtPaths = [p for p in textGen()]\n",
    "\n",
    "    for i in range(count):\n",
    "        w = []\n",
    "        t = []\n",
    "        for j in range(voicesPerSample):\n",
    "\n",
    "            random_file = np.random.randint(0, len(allWavPaths))\n",
    "            sentences, timestamps = split_sentence(\n",
    "                textgrid.TextGrid.fromFile(allTxtPaths[random_file]))\n",
    "            random_phrase = np.random.randint(0, len(timestamps))\n",
    "            ts = timestamps[random_phrase]\n",
    "            t.append(ts)\n",
    "            w.append(loadWavFile(allWavPaths[random_file], ts[0], ts[2]))\n",
    "\n",
    "        yield w, t\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Room Functions\"\"\"\n",
    "def generate_room_characteristics():\n",
    "    dims = rt60 = absorption = 0\n",
    "    if randomize_room:\n",
    "        dims: list(int) = [np.random.randint(room_dim_ranges[i, 0], room_dim_ranges[i, 1])\n",
    "                           for i in range(len(room_dim_ranges[:]))]\n",
    "\n",
    "        rt60: float = rt60_range[0] + \\\n",
    "            (rt60_range[1]-rt60_range[0])*np.random.random()\n",
    "\n",
    "        absorption: float = absorption_range[0] + \\\n",
    "            (absorption_range[1]-absorption_range[0]) * np.random.random()\n",
    "\n",
    "    else:\n",
    "        dims = normal_room_dim\n",
    "        rt60 = normal_rt60\n",
    "        absorption = normal_absorption\n",
    "\n",
    "    return dims, rt60, absorption\n",
    "\n",
    "def random_position_in_room(roomDims):\n",
    "    x = np.random.random() * (roomDims[0]-1) + 0.5\n",
    "    y = np.random.random() * (roomDims[1]-1) + 0.5\n",
    "    z = 1.73\n",
    "    return [x, y, z]\n",
    "\n",
    "\n",
    "def positions_too_close(positions):\n",
    "    for a in positions[1:]:\n",
    "        for b in positions[1:]:\n",
    "            if a == b:\n",
    "                continue\n",
    "            if distance(a, b) < 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# returns angle between two points in degrees\n",
    "def get_angle(a, b):\n",
    "    # turns clockwise angle into counter-clockwise\n",
    "    def angle_trunc(a):\n",
    "        while a < 0.0:\n",
    "            a += math.pi * 2\n",
    "        return a\n",
    "\n",
    "    deltaY = b[1] - a[1]\n",
    "    deltaX = b[0] - a[0]\n",
    "    return math.degrees(angle_trunc(math.atan2(deltaY, deltaX)))\n",
    "\n",
    "\n",
    "def transform_to_directivities(positions):\n",
    "    dirs = []\n",
    "    print('pos to trans')\n",
    "    print(positions)\n",
    "    middle = [avg(np.transpose(positions)[i]) for i in range(len(positions[0]))]\n",
    "\n",
    "    posi = positions[0]\n",
    "    # Winkel aus Vogelperspeltive, in die Listnener guckt\n",
    "    baseAngle = get_angle(posi[:2], middle[:2])\n",
    "\n",
    "    # linkes und rechtes ohr des LIsteners\n",
    "    dirs.append([(baseAngle + 90) % 360, 90])  # bug somewhere here\n",
    "    dirs.append([(baseAngle + 270) % 360, 90])\n",
    "\n",
    "    for pos in positions[2:]:\n",
    "        dirs.append([get_angle(pos, posi), 90])\n",
    "\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def random_persons_in_room(roomDims, count):\n",
    "    def pos_in_room(count):\n",
    "        pos = []\n",
    "        for i in range(count):\n",
    "            pos.append(random_position_in_room(roomDims))\n",
    "        return pos\n",
    "\n",
    "    # do while: erzeuge solange bis gÃ¼ltiges ergebnis\n",
    "    positions = pos_in_room(count)\n",
    "    while(positions_too_close(positions)):\n",
    "        positions = pos_in_room(count)\n",
    "    positions[0] = positions[1]\n",
    "    scatterplot3d(positions,roomDims)\n",
    "    return positions, transform_to_directivities(positions)\n",
    "\n",
    "# calculates mic positions depentend of middle point\n",
    "\n",
    "\n",
    "def get_pos_mics(position, dir):\n",
    "\n",
    "    x = point_pos(position[0], head_size/2, dir[0][0])\n",
    "    y = point_pos(position[0], head_size/2, dir[1][0])\n",
    "\n",
    "    return [x, y]\n",
    "\n",
    "# calculates mic position depentend of middle point\n",
    "\n",
    "\n",
    "def point_pos(x, d, theta):\n",
    "    theta_rad = math.pi/2 - math.radians(theta)\n",
    "    return [x[0] + d * math.cos(theta_rad), x[1] + d*math.sin(theta_rad), x[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"WAV and audio Mixing\"\"\"\n",
    "def loadWavFile(path, offset=0, duration=None):\n",
    "    wav, sr = librosa.load(path, sr=sampleRate, offset=offset,\n",
    "                           duration=duration, mono=True)\n",
    "\n",
    "    wav = librosa.util.normalize(wav)\n",
    "    return wav\n",
    "\n",
    "\n",
    "def makeCardioid(direction):\n",
    "    return CardioidFamily(\n",
    "        orientation=DirectionVector(\n",
    "            azimuth=direction[0], colatitude=direction[1], degrees=True),\n",
    "        pattern_enum=DirectivityPattern.CARDIOID,\n",
    "    )\n",
    "\n",
    "\n",
    "def createRoom(room_dim, rt60,absorption):\n",
    "    e_absortion, max_order = pra.inverse_sabine(rt60, room_dim)\n",
    "    room: pra.ShoeBox = pra.ShoeBox(room_dim, fs=sampleRate, materials=pra.Material(\n",
    "        e_absortion), absorption=absorption, max_order=max_order)\n",
    "    return room\n",
    "\n",
    "def mixRoom(room,listenerPositions, listenerDirs, speakerPositions, speakerDirs, wavs):\n",
    "    listenerDirs = list(map(lambda d: makeCardioid(d), listenerDirs))\n",
    "    speakerDirs = list(map(lambda d: makeCardioid(d), speakerDirs))\n",
    "\n",
    "    mic_array = pra.MicrophoneArray(\n",
    "        np.c_[listenerPositions[0], listenerPositions[1]], directivity=listenerDirs, fs=sampleRate)\n",
    "\n",
    "    for i in range(len(speakerPositions)):\n",
    "        room.add_source(\n",
    "            position=speakerPositions[i], directivity=speakerDirs[i], signal=wavs[i])\n",
    "    room.add_microphone_array(mic_array)\n",
    "\n",
    "    return room\n",
    "\n",
    "def exportRoom(room:pra.ShoeBox, filepath):\n",
    "    room.mic_array.to_wav(filepath, norm=True, bitdepth=np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Exporting training data\"\"\"\n",
    "\n",
    "# sampleNr: int, speakerIdsList:int[n], positionList:float[n+2], directions:float[n+2], timeframes:floats[n][2]\n",
    "def createJsonData(sampleNr, speakerIdsList, positionList, directions, timeframes):\n",
    "    speakers = []\n",
    "    for i in range(len(speakerIdsList)):\n",
    "        speaker = {\n",
    "            'id': speakerIdsList[i],\n",
    "            'position': positionList[i+2],\n",
    "            'direction': directions[i+2],\n",
    "            'startTime': timeframes[i][ 0],\n",
    "            'endTime': timeframes[i][ 1],\n",
    "            'duration': timeframes[i][ 2]\n",
    "        }\n",
    "        speakers.append(speaker)\n",
    "\n",
    "    return {\n",
    "        'comment': 'direction: [azimuth, colatitude]',\n",
    "        'sample': {\n",
    "            'id': sampleNr,\n",
    "            'speakers': speakers,\n",
    "            'listener': {\n",
    "                'position': positionList[0],\n",
    "                'directionLeft': directions[0],\n",
    "                'directionRight': directions[1]\n",
    "            },\n",
    "            'source': source_dataset\n",
    "        }\n",
    "    }\n",
    "\n",
    "def createFolder(targetFolder):\n",
    "    try:\n",
    "        os.mkdir(targetFolder)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        shutil.rmtree(targetFolder)\n",
    "        os.mkdir(targetFolder)\n",
    "\n",
    "def exportSample(sampleNr,room,wavs,json_data):\n",
    "    folder = target_dir+'/'+str(sampleNr)\n",
    "    createFolder(folder)\n",
    "    exportRoom(room, folder+'/room.wav')\n",
    "    for i in range(len(wavs)):\n",
    "        soundfile.write(folder+f'/speaker{i}.wav', wavs[i], sampleRate)\n",
    "    with open(folder+'/description.json', 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MAIN\"\"\"\n",
    "\n",
    "def generate():\n",
    "    sampleNr = skipSamples\n",
    "    gen = VoiceLineGeneratorKEC(1, speakers_in_room)\n",
    "    for (wavs, timestamps) in gen:\n",
    "        #creating parameters\n",
    "        sampleNr += 1\n",
    "        dims, rt60, absorption = generate_room_characteristics()\n",
    "        room = createRoom(dims, rt60, absorption)\n",
    "        pos, dirs = random_persons_in_room(dims, speakers_in_room+2)\n",
    "        listener_pos = get_pos_mics(pos[:2], dirs[:2])\n",
    "        print(listener_pos)\n",
    "        #creating data\n",
    "        room = mixRoom(room, listener_pos, dirs[:2], pos[2:], dirs[2:], wavs)\n",
    "        room.simulate()\n",
    "        json_data = createJsonData(sampleNr, range(\n",
    "            len(wavs)), pos, dirs, timestamps)\n",
    "\n",
    "        exportSample(sampleNr,room,wavs,json_data)\n",
    "\n",
    "        msg = f'Generated Room Nr.{sampleNr}.'\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb449e53dd372215b80e7ed3be416481dfeee2fd742bfe6369d3120d1b21554b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
