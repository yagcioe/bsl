{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Script parameters\n",
    "\"\"\"\n",
    "target_amount_samples = 250\n",
    "skipSamples = 0\n",
    "target_dir='workspace/data/training/KEC'\n",
    "\n",
    "\n",
    "\"Persons\"\n",
    "speakers_in_room = 1\n",
    "\n",
    "\"ROOM\"\n",
    "randomize_room = False\n",
    "# room generation will be laplace distributed in these intervalls [width, length, height]\n",
    "normal_room_dim = [15, 20, 4]\n",
    "room_dim_ranges = [[3, 30], [3, 30], [2.5, 5]]\n",
    "\n",
    "# The amout Walls absorb Sound\n",
    "normal_absorption = 1.2\n",
    "absorption_range = [1, 2]\n",
    "\n",
    "# the time it take until the signal drops by 60 dB\n",
    "normal_rt60 = 0.5\n",
    "rt60_range = [0.05, 0, 75]\n",
    "\n",
    "\"AUdio\"\n",
    "sampleRate = 16000\n",
    "#total_length = 30\n",
    "max_audio_length = 30\n",
    "#min_audio_length = 5\n",
    "min_characters = 20\n",
    "\n",
    "\n",
    "# 'nice to have' for data generation\n",
    "source_dataset = 'KEC - https://clarin.phonetik.uni-muenchen.de/BASRepository/index.php?target=Public/Corpora/KEC/KEC.1.php'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_filter(x):\n",
    "    return True if 'rec' in x else False\n",
    "\n",
    "\n",
    "def wav_filter(x):\n",
    "    return True if '.wav' in x else False\n",
    "\n",
    "\n",
    "def txt_filter(x):\n",
    "    return True if '.TextGrid' in x else False\n",
    "\n",
    "\n",
    "def as_filter(x):\n",
    "    return True if 'AS' in x else False\n",
    "\n",
    "\n",
    "def idx_filter_txt(x, y):\n",
    "    return True if x[len(x) - 10] == y else False\n",
    "\n",
    "\n",
    "def rec_filter(x):\n",
    "    return True if 'rec' in x else False\n",
    "\n",
    "\n",
    "def norm2(x):\n",
    "    return np.sum(map(lambda y: y**2, x))\n",
    "\n",
    "\n",
    "def distance(x,y):\n",
    "    return norm2(x-y)\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FileGeneratorsKEC():\n",
    "    src = '/workspace/data/KEC'\n",
    "    recFolders = list(filter(lambda f: rec_filter(f), os.listdir(src)))\n",
    "    allWavfiles = []\n",
    "    alltxtFiles = []\n",
    "    for rec in recFolders:\n",
    "        currentDir = src+\"/\"+rec\n",
    "\n",
    "        wavFilesOfFolder = list(filter(lambda f: wav_filter(f), os.listdir(currentDir)))\n",
    "        wavFilesOfFolder = list(map(lambda f: currentDir+\"/\"+f, wavFilesOfFolder))\n",
    "        allWavfiles.extend(wavFilesOfFolder)\n",
    "\n",
    "        txtFilesOfFolder = list(filter(lambda f: txt_filter(f), os.listdir(currentDir)))\n",
    "        txtFilesOfFolder = list(map(lambda f: currentDir+\"/\"+f, txtFilesOfFolder))\n",
    "        alltxtFiles.extend(txtFilesOfFolder)\n",
    "    \n",
    "    def wavGen():\n",
    "        for file in allWavfiles:\n",
    "            yield file\n",
    "    def textGen():\n",
    "        for file in alltxtFiles:\n",
    "            yield file\n",
    "\n",
    "    return wavGen, textGen\n",
    "\n",
    "def VoiceLineGeneratorKEC(wavGen,textGen):\n",
    "    # Todo\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_room_characteristics():\n",
    "    dims,rt60,absorption=0\n",
    "    if randomize_room:\n",
    "        dims: list(int) = [np.random.randint(room_dim_ranges[i, 0], room_dim_ranges[i, 1])\n",
    "                           for i in range(len(room_dim_ranges[:]))]\n",
    "\n",
    "        rt60: float = rt60_range[0] + \\\n",
    "            (rt60_range[1]-rt60_range[0])*np.random.random()\n",
    "\n",
    "        absorption: float = absorption_range[0] + \\\n",
    "            (absorption_range[1]-absorption_range[0]) * np.random.random()\n",
    "\n",
    "    else:\n",
    "        dims = normal_room_dim\n",
    "        rt60 = normal_rt60\n",
    "        absorption = normal_absorption\n",
    "\n",
    "    return dims, rt60, absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_position_in_room(roomDims):\n",
    "    x = np.random.random() * (roomDims[0]-1) + 0.5\n",
    "    y = np.random.random() * (roomDims[1]-1) + 0.5\n",
    "    z = 1.73\n",
    "    return [x, y, z]\n",
    "\n",
    "\n",
    "def positions_too_close(positions):\n",
    "    for a in positions[1:]:\n",
    "        for b in positions[1:]:\n",
    "            if a == b:\n",
    "                continue\n",
    "            if distance(a, b) < 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# returns angle between two points in degrees\n",
    "def get_angle(a, b):\n",
    "    # turns clockwise angle into counter-clockwise\n",
    "    def angle_trunc(a):\n",
    "        while a < 0.0:\n",
    "            a += math.pi * 2\n",
    "        return a\n",
    "\n",
    "    deltaY = b[1] - a[1]\n",
    "    deltaX = b[0] - a[0]\n",
    "    return math.degrees(angle_trunc(math.atan2(deltaY, deltaX)))\n",
    "\n",
    "\n",
    "def transform_to_directivities(positions):\n",
    "    dirs = []\n",
    "    middle = [avg(positions[:, i]) for i in len(positions[0])]\n",
    "\n",
    "    posi = positions[0]\n",
    "    # Winkel aus Vogelperspeltive, in die Listnener guckt\n",
    "    baseAngle = get_angle(posi[:2],middle[:2])\n",
    "\n",
    "    # linkes und rechtes ohr des LIsteners\n",
    "    dirs.append([(baseAngle + 90) % 360, 90])  # bug somewhere here\n",
    "    dirs.append([(baseAngle + 270) % 360, 90])\n",
    "\n",
    "    for pos in positions[2:]:\n",
    "        dirs.append([get_angle(pos,posi), 90])\n",
    "\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def random_persons_in_room(roomDims):\n",
    "    def pos_in_room(count):\n",
    "        pos = []\n",
    "        for i in range(count):\n",
    "            pos.append(random_position_in_room(roomDims))\n",
    "        return pos\n",
    "\n",
    "    # do while: erzeuge solange bis gÃ¼ltiges ergebnis\n",
    "    positions = pos_in_room(speakers_in_room)\n",
    "    while(positions_too_close(positions)):\n",
    "        positions = pos_in_room(speakers_in_room)\n",
    "    positions[0] = positions[1]\n",
    "\n",
    "    return positions, transform_to_directivities(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWavFile(path, offset=0, duration=None):\n",
    "    wav, sr = librosa.load(path, sr=sampleRate, offset=offset,\n",
    "                           duration=duration, mono=True)\n",
    "\n",
    "    wav = librosa.util.normalize(wav)\n",
    "    return wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_words_with_timestamps(timestamps, j, words, word_ts):\n",
    "    max_as = timestamps[j][1]\n",
    "    min_as = timestamps[j][0]\n",
    "\n",
    "    words2 = get_words(words, word_ts, [min_as, max_as])\n",
    "\n",
    "    return words2\n",
    "\n",
    "\n",
    "# retrives words with relative timestamp\n",
    "def get_words(words, timestamps, interval):\n",
    "\n",
    "    start = [(idx, time) for idx, time in enumerate(\n",
    "        timestamps) if time[0] == interval[0]][0]\n",
    "    end = [(idx, time) for idx, time in enumerate(\n",
    "        timestamps) if time[1] == interval[1]][0]\n",
    "\n",
    "    start_time = timestamps[start[0]][0]\n",
    "\n",
    "    words = words[start[0]:end[0]+1]\n",
    "    timestamps = timestamps[start[0]:end[0]+1]\n",
    "\n",
    "    for idx, w in enumerate(words):\n",
    "        words[idx] = [w, [timestamps[idx][0] -\n",
    "                          start_time, timestamps[idx][1] - start_time]]\n",
    "    return words\n",
    "\n",
    "# splits text file in parts\n",
    "\n",
    "\n",
    "def split_sentence(textGrid):\n",
    "\n",
    "    helper = 0\n",
    "    sentences, timestamp = [], []\n",
    "    words, w_timestamp = [], []\n",
    "    sentence = ''\n",
    "    sentence_start = 0\n",
    "    counter = 0\n",
    "\n",
    "    for t in textGrid[0]:\n",
    "        if helper > t.maxTime:\n",
    "            break\n",
    "\n",
    "        text = t.mark\n",
    "        maxTime = t.maxTime\n",
    "        minTime = t.minTime\n",
    "        helper = maxTime\n",
    "        sentence += ' ' + text\n",
    "        words.append(text)\n",
    "        w_timestamp.append([minTime, maxTime])\n",
    "        counter += 1\n",
    "\n",
    "        if '<P>' in text and maxTime - sentence_start < max_audio_length and maxTime - sentence_start >= 5 and len(sentence) > min_characters:\n",
    "            sentences.append(sentence)\n",
    "            sentence = ''\n",
    "            timestamp.append([sentence_start, maxTime])\n",
    "            sentence_start = maxTime\n",
    "\n",
    "        elif '<P>' in text:\n",
    "            sentence = ''\n",
    "            sentence_start = maxTime\n",
    "    return sentences, timestamp, words, w_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleNr: int, speakerIdsList:int[n], positionList:float[n+2], directions:float[n+2], timeframes:floats[n][2]\n",
    "def createJsonData(sampleNr, speakerIdsList, positionList, directions, timeframes):\n",
    "    speakers = []\n",
    "    for i in range(len(speakerIdsList)):\n",
    "        speaker = {\n",
    "            'id': speakerIdsList[i],\n",
    "            'position': positionList[i+2],\n",
    "            'direction': directions[i+2],\n",
    "            'startTime': timeframes[i, 0],\n",
    "            'duration': timeframes[i, 1]\n",
    "        }\n",
    "        speakers.append(speaker)\n",
    "        \n",
    "    return {\n",
    "        'comment': 'direction: [azimuth, colatitude]',\n",
    "        'sample': {\n",
    "            'id': sampleNr,\n",
    "            'speakers': speakers,\n",
    "            'listener': {\n",
    "                'position': positionList[0],\n",
    "                'directionLeft': directions[0],\n",
    "                'directionRight': directions[1]\n",
    "\n",
    "            },\n",
    "            'source': source_dataset\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def generate():\n",
    "    global skipSamples\n",
    "    wavGen, txtGen = FileGeneratorsKEC()\n",
    "    for wav in wavGen():\n",
    "        if(skipSamples > 0):\n",
    "            skipSamples -= 1\n",
    "            continue\n",
    "\n",
    "        loadWavFile(wav, 0, 10)\n",
    "        sentences_as, timestamps_as, word_as, word_ts_as = split_sentence(txtGen().__next__())\n",
    "        print(sentences_as)\n",
    "        print(timestamps_as),\n",
    "        print(word_as)\n",
    "        print(word_ts_as)\n",
    "        break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb449e53dd372215b80e7ed3be416481dfeee2fd742bfe6369d3120d1b21554b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
