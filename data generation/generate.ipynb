{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "import json\n",
    "import textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Script parameters\n",
    "\"\"\"\n",
    "target_amount_samples = 250\n",
    "skipSamples = 0\n",
    "target_dir = 'workspace/data/training/KEC'\n",
    "\n",
    "\n",
    "\"Persons\"\n",
    "speakers_in_room = 1\n",
    "\n",
    "\"ROOM\"\n",
    "randomize_room = False\n",
    "# room generation will be laplace distributed in these intervalls [width, length, height]\n",
    "normal_room_dim = [15, 20, 4]\n",
    "room_dim_ranges = [[3, 30], [3, 30], [2.5, 5]]\n",
    "\n",
    "# The amout Walls absorb Sound\n",
    "normal_absorption = 1.2\n",
    "absorption_range = [1, 2]\n",
    "\n",
    "# the time it take until the signal drops by 60 dB\n",
    "normal_rt60 = 0.5\n",
    "rt60_range = [0.05, 0, 75]\n",
    "\n",
    "\"AUdio\"\n",
    "sampleRate = 16000\n",
    "#total_length = 30\n",
    "max_audio_length = 30\n",
    "#min_audio_length = 5\n",
    "min_characters_per_sentence = 20\n",
    "\n",
    "\n",
    "# 'nice to have' for data generation\n",
    "source_dataset = 'KEC - https://clarin.phonetik.uni-muenchen.de/BASRepository/index.php?target=Public/Corpora/KEC/KEC.1.php'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_filter(x):\n",
    "    return True if 'rec' in x else False\n",
    "\n",
    "\n",
    "def wav_filter(x):\n",
    "    return True if '.wav' in x else False\n",
    "\n",
    "\n",
    "def txt_filter(x):\n",
    "    return True if '.TextGrid' in x else False\n",
    "\n",
    "\n",
    "def as_filter(x):\n",
    "    return True if 'AS' in x else False\n",
    "\n",
    "\n",
    "def idx_filter_txt(x, y):\n",
    "    return True if x[len(x) - 10] == y else False\n",
    "\n",
    "\n",
    "def rec_filter(x):\n",
    "    return True if 'rec' in x else False\n",
    "\n",
    "\n",
    "def norm2(x):\n",
    "    return np.sum(map(lambda y: y**2, x))\n",
    "\n",
    "\n",
    "def distance(x, y):\n",
    "    return norm2(x-y)\n",
    "\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FileGeneratorsKEC():\n",
    "    src = '/workspace/data/KEC'\n",
    "    recFolders = list(filter(lambda f: rec_filter(f), os.listdir(src)))\n",
    "    allWavfiles = []\n",
    "    alltxtFiles = []\n",
    "    for rec in recFolders:\n",
    "        currentDir = src+\"/\"+rec\n",
    "\n",
    "        wavFilesOfFolder = list(\n",
    "            filter(lambda f: wav_filter(f), os.listdir(currentDir)))\n",
    "        wavFilesOfFolder = list(\n",
    "            map(lambda f: currentDir+\"/\"+f, wavFilesOfFolder))\n",
    "        allWavfiles.extend(wavFilesOfFolder)\n",
    "\n",
    "        txtFilesOfFolder = list(\n",
    "            filter(lambda f: txt_filter(f), os.listdir(currentDir)))\n",
    "        txtFilesOfFolder = list(\n",
    "            map(lambda f: currentDir+\"/\"+f, txtFilesOfFolder))\n",
    "        alltxtFiles.extend(txtFilesOfFolder)\n",
    "\n",
    "    def wavGen():\n",
    "        for file in allWavfiles:\n",
    "            yield file\n",
    "\n",
    "    def textGen():\n",
    "        for file in alltxtFiles:\n",
    "            yield file\n",
    "\n",
    "    return wavGen, textGen\n",
    "\n",
    "# splits text file in parts\n",
    "def split_sentence(textGrid):\n",
    "    currentTime = 0\n",
    "    sentence_start = 0\n",
    "    sentences, timestamp = [], []\n",
    "    sentence = ''\n",
    "\n",
    "    for t in textGrid[0]:\n",
    "        if currentTime > t.maxTime:\n",
    "            break\n",
    "\n",
    "        currentTime = t.maxTime\n",
    "        sentence += ' ' + t.mark\n",
    "        duration = np.round(t.maxTime - sentence_start, 5)\n",
    "\n",
    "        if '<P>' in t.mark:\n",
    "            if duration < max_audio_length and duration >= 5 and len(sentence) > min_characters_per_sentence:\n",
    "                sentences.append(sentence.strip())\n",
    "                timestamp.append([sentence_start, t.maxTime, duration])\n",
    "            sentence = ''\n",
    "            sentence_start = t.maxTime\n",
    "\n",
    "    return sentences, timestamp\n",
    "\n",
    "def VoiceLineGeneratorKEC(count):\n",
    "    voiceLines = []\n",
    "    wavGen, textGen = FileGeneratorsKEC()\n",
    "    allWavPaths = [p for p in wavGen()]\n",
    "    allTxtPaths = [p for p in txtGen()]\n",
    "\n",
    "    for i in range(count):\n",
    "        random_file = np.random.random_int(0, len(allWavPaths))\n",
    "        sentences, timestamps = split_sentence(textgrid.Textgrid.fromFile(allTxtPaths[random_file]))\n",
    "        random_phrase = np.random.random_int(0, len(sentences))\n",
    "        \n",
    "        yield sentences[random_phrase], timestamps[random_phrase], loadWavFile(allWavPaths[random_file], timestamps[0], timestamps[2])\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_room_characteristics():\n",
    "    dims,rt60,absorption=0\n",
    "    if randomize_room:\n",
    "        dims: list(int) = [np.random.randint(room_dim_ranges[i, 0], room_dim_ranges[i, 1])\n",
    "                           for i in range(len(room_dim_ranges[:]))]\n",
    "\n",
    "        rt60: float = rt60_range[0] + \\\n",
    "            (rt60_range[1]-rt60_range[0])*np.random.random()\n",
    "\n",
    "        absorption: float = absorption_range[0] + \\\n",
    "            (absorption_range[1]-absorption_range[0]) * np.random.random()\n",
    "\n",
    "    else:\n",
    "        dims = normal_room_dim\n",
    "        rt60 = normal_rt60\n",
    "        absorption = normal_absorption\n",
    "\n",
    "    return dims, rt60, absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_position_in_room(roomDims):\n",
    "    x = np.random.random() * (roomDims[0]-1) + 0.5\n",
    "    y = np.random.random() * (roomDims[1]-1) + 0.5\n",
    "    z = 1.73\n",
    "    return [x, y, z]\n",
    "\n",
    "\n",
    "def positions_too_close(positions):\n",
    "    for a in positions[1:]:\n",
    "        for b in positions[1:]:\n",
    "            if a == b:\n",
    "                continue\n",
    "            if distance(a, b) < 1:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# returns angle between two points in degrees\n",
    "def get_angle(a, b):\n",
    "    # turns clockwise angle into counter-clockwise\n",
    "    def angle_trunc(a):\n",
    "        while a < 0.0:\n",
    "            a += math.pi * 2\n",
    "        return a\n",
    "\n",
    "    deltaY = b[1] - a[1]\n",
    "    deltaX = b[0] - a[0]\n",
    "    return math.degrees(angle_trunc(math.atan2(deltaY, deltaX)))\n",
    "\n",
    "\n",
    "def transform_to_directivities(positions):\n",
    "    dirs = []\n",
    "    middle = [avg(positions[:, i]) for i in len(positions[0])]\n",
    "\n",
    "    posi = positions[0]\n",
    "    # Winkel aus Vogelperspeltive, in die Listnener guckt\n",
    "    baseAngle = get_angle(posi[:2],middle[:2])\n",
    "\n",
    "    # linkes und rechtes ohr des LIsteners\n",
    "    dirs.append([(baseAngle + 90) % 360, 90])  # bug somewhere here\n",
    "    dirs.append([(baseAngle + 270) % 360, 90])\n",
    "\n",
    "    for pos in positions[2:]:\n",
    "        dirs.append([get_angle(pos,posi), 90])\n",
    "\n",
    "    return dirs\n",
    "\n",
    "\n",
    "def random_persons_in_room(roomDims):\n",
    "    def pos_in_room(count):\n",
    "        pos = []\n",
    "        for i in range(count):\n",
    "            pos.append(random_position_in_room(roomDims))\n",
    "        return pos\n",
    "\n",
    "    # do while: erzeuge solange bis gÃ¼ltiges ergebnis\n",
    "    positions = pos_in_room(speakers_in_room)\n",
    "    while(positions_too_close(positions)):\n",
    "        positions = pos_in_room(speakers_in_room)\n",
    "    positions[0] = positions[1]\n",
    "\n",
    "    return positions, transform_to_directivities(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWavFile(path, offset=0, duration=None):\n",
    "    wav, sr = librosa.load(path, sr=sampleRate, offset=offset,\n",
    "                           duration=duration, mono=True)\n",
    "\n",
    "    wav = librosa.util.normalize(wav)\n",
    "    return wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampleNr: int, speakerIdsList:int[n], positionList:float[n+2], directions:float[n+2], timeframes:floats[n][2]\n",
    "def createJsonData(sampleNr, speakerIdsList, positionList, directions, timeframes):\n",
    "    speakers = []\n",
    "    for i in range(len(speakerIdsList)):\n",
    "        speaker = {\n",
    "            'id': speakerIdsList[i],\n",
    "            'position': positionList[i+2],\n",
    "            'direction': directions[i+2],\n",
    "            'startTime': timeframes[i, 0],\n",
    "            'endTime': timeframes[i, 1],\n",
    "            'duration': timeframes[i,2]\n",
    "        }\n",
    "        speakers.append(speaker)\n",
    "        \n",
    "    return {\n",
    "        'comment': 'direction: [azimuth, colatitude]',\n",
    "        'sample': {\n",
    "            'id': sampleNr,\n",
    "            'speakers': speakers,\n",
    "            'listener': {\n",
    "                'position': positionList[0],\n",
    "                'directionLeft': directions[0],\n",
    "                'directionRight': directions[1]\n",
    "            },\n",
    "            'source': source_dataset\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def generate():\n",
    "    global skipSamples\n",
    "    wavGen, txtGen = FileGeneratorsKEC()\n",
    "    for wav in wavGen():\n",
    "        if(skipSamples > 0):\n",
    "            skipSamples -= 1\n",
    "            continue\n",
    "\n",
    "        loadWavFile(wav, 0, 10)\n",
    "        tg = textgrid.TextGrid.fromFile(txtGen().__next__())\n",
    "        sentences, timestamps = split_sentence(tg)\n",
    "        print(sentences)\n",
    "        print(timestamps)\n",
    "        break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb449e53dd372215b80e7ed3be416481dfeee2fd742bfe6369d3120d1b21554b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
